# -*- coding: utf-8 -*-
"""Sarvjeet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dk83kRDkmeUtx9gOJ8190Mqr3278UgPU
"""

from google.colab import drive
drive.mount('/content/drive')

from google.colab import drive
drive.mount('/content/gdrive')

import zipfile

dataset_path="/content/gdrive/My Drive/612927_1105074_bundle_archive.zip"
zfile=zipfile.ZipFile(dataset_path)
zfile.extractall()

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x

import os
import numpy as np
import pandas as pd
import tensorflow
import matplotlib.pyplot as plt

import keras

from tensorflow.keras.preprocessing.image import load_img

from tensorflow.keras.applications import ResNet50
from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D
from sklearn.datasets import load_files
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization

import cv2

from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions
from tensorflow.keras.preprocessing import image
from keras_preprocessing.image import ImageDataGenerator

def load_dataset(dataset_path):
  data = load_files(dataset_path)
  files = np.array(data['filenames'])
  targets = np.array(data['target'])
  target_labels = np.array(data['target_names'])
  return files,targets,target_labels

train_path = '/content/gdrive/My Drive/maskdata/train'        
test_path = '/content/gdrive/My Drive/maskdata/test' 

x_train, y_train, target_labels = load_dataset(train_path)
x_test, y_test,_ = load_dataset(test_path)

print('Training set size : ' , x_train.shape[0])
print('Testing set size : ', x_test.shape[0])

image = load_img(x_train[2])
plt.imshow(image)

im = cv2.imread(x_train[2])
h, w, c = im.shape
print('width:  ', w)
print('height: ', h)
print('channel:', c)

num_classes = 2
FAST_RUN       = False
IMAGE_WIDTH    =64
IMAGE_HEIGHT   =64
batch_size=50
image_size = 64
epoch =15
IMAGE_SIZE     =(IMAGE_WIDTH, IMAGE_HEIGHT)
IMAGE_CHANNELS =3
DROP_OUT_VALUE =0.1
FILTER_SIZE    =(3, 3)
POOL_SIZE      =(2, 2)

model = tensorflow.keras.Sequential()

model.add(Conv2D(32, FILTER_SIZE, activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNELS)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=POOL_SIZE))
#model.add(Dropout(DROP_OUT_VALUE))

model.add(Conv2D(64, FILTER_SIZE, activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=POOL_SIZE))
model.add(Dropout(DROP_OUT_VALUE))

model.add(Conv2D(128, FILTER_SIZE, activation='relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=POOL_SIZE))
model.add(Dropout(DROP_OUT_VALUE))


model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(DROP_OUT_VALUE))
model.add(Dense(2, activation='softmax')) # 2 because we have cat and dog classes

model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])

model.summary()

data_generator = ImageDataGenerator(preprocessing_function=preprocess_input,horizontal_flip=True,
                                   width_shift_range = 0.2,
                                   height_shift_range = 0.2,
                                    rescale = 1/255.0)


train_generator = data_generator.flow_from_directory(
        train_path,
        target_size=(image_size, image_size),
        batch_size=batch_size,
        class_mode='categorical')

validation_generator = data_generator.flow_from_directory(test_path,target_size=(image_size, image_size),
        class_mode='categorical')

history=model.fit_generator(
        train_generator,
        epochs=epoch, 
        validation_data=validation_generator,
        validation_steps=1)

#Loss
plt.plot(history.history['loss'],'r')
plt.plot(history.history['val_loss'])
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['training loss', 'testing loss'])
plt.show()

#Accuracy
plt.plot(history.history['acc'],'r')
plt.plot(history.history['val_acc'])
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['training accuracy', 'testing accuracy'])
plt.show()

model.save("mask.h5")

img = cv2.imread('/content/gdrive/My Drive/people-beauty-lifestyle-concept-shot-260nw-662171107.webp')
face_clsfr=cv2.CascadeClassifier('/content/gdrive/My Drive/haarcascade_frontalface_default.xml')

gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
faces=face_clsfr.detectMultiScale(gray,1.3,5)  

for (x,y,w,h) in faces:
  face_img=img[y:y+w,x:x+w]
  resized=cv2.resize(face_img,(64,64))
  normalized=resized
  reshaped=np.reshape(normalized,(1,64,64,3))
  result=model.predict(reshaped)

  label=np.argmax(result,axis=1)[0]
  acc=round(np.max(result,axis=1)[0]*100,2)

result

acc

dict0 = {"mask": 0,
         "without_mask": 1}

plt.imshow(normalized)

print(list(dict0.keys())[list(dict0.values()).index(label)])

